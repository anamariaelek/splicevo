# Fast training configuration - optimized for speed

# Device configuration
device: cuda
cpu_threads: 8
cudnn_benchmark: true
gpu_memory_fraction: 0.8  # Use more GPU memory for larger batches

# Data configuration
data:
  path: /home/elek/sds/sd17d003/Anamaria/splicevo/data/splits_full_5kb/mouse_rat_human/
  use_mmap: true
  train_split: 0.8
  normalization_method: none
  usage_types: ['sse']

# Output configuration
output:
  checkpoint_dir: /home/elek/sds/sd17d003/Anamaria/splicevo/models/transformer/full_mouse_rat_human_5kb_fast
  use_tensorboard: true

# Model architecture - slightly smaller for faster training
model:
  embed_dim: 128
  num_resblocks: 12      # Reduced from 16 (25% fewer layers)
  dilation_strategy: alternating
  alternate: 4 
  bottleneck_dim: 128
  num_heads: 8
  num_classes: 3
  context_len: 450
  dropout: 0.3           # Reduced from 0.4

# Training configuration
training:
  # Optimizer
  learning_rate: 2.0e-4  # Increased for larger batch size
  weight_decay: 1.0e-3
  warmup_steps: 1500     # Reduced warmup

  # Loss for splice site prediction
  splice_loss_type: 'focal'
  
  # Class weights for cross_entropy loss (auto-calculate from class frequencies)
  class_weights: 'inverse'  # Use 'balanced', 'inverse', or specify [w0, w1, w2]

  # Focal Loss parameters - optimized
  focal_alpha: [0.1, 1.0, 1.0]
  focal_gamma: 3.0
  
  # Masked Focal Loss - reduced window for speed
  use_masked_loss: true
  context_window: 80     # Reduced from 100 (fewer positions to compute)

  # Loss for splice site usage (SSE)
  usage_loss_type: 'weighted_mse'  # Options: 'mse', 'bce', 'weighted_mse' or 'hybrid'

  # Weighted MSE parameters
  weighted_mse_extreme_low: 0.1        # Values < this are extreme near zero
  weighted_mse_extreme_high: 0.9       # Values > this are extreme near one
  weighted_mse_extreme_weight: 5.0     # Weight for errors in extreme values (weight for other values=1)

  # Hybrid loss parameters
  hybrid_extreme_low: 0.1       # Values < this classified as "zero"
  hybrid_extreme_high: 0.9      # Values > this classified as "one"
  hybrid_class_weight: 0.8      # Weight for classification component
  hybrid_reg_weight: 0.2        # Weight for regression component

  # How to combine splice site and usage loss
  splice_weight: 0.5
  usage_weight: 0.5
  
  # Training loop
  n_epochs: 50
  early_stopping_patience: 5
  
  # Memory optimization
  use_amp: true
  gradient_accumulation_steps: 1  # No accumulation with larger batch
  
  # DataLoader - maximally optimized
  dataloader:
    batch_size: 64       # Large batch for maximum throughput
    num_workers: 16      # More workers for data loading
    prefetch_factor: 6   # Aggressive prefetching
