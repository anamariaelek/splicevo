{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4bcf21b",
   "metadata": {},
   "source": [
    "# Train small Splicevo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ca592f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9090ebdc",
   "metadata": {},
   "source": [
    "## Simulate small dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d65ddbf",
   "metadata": {},
   "source": [
    "To train a Splicevo model, we need the following data:\n",
    "\n",
    "- Input DNA sequences of shape `B, L, 4` (one-hot encoded)\n",
    "- Labels of shape `B, L` corresponding to splice site annotations (0=not a splice site, 1=splice donor, 2=splice acceptor)\n",
    "- SSE values of shape `B, L, N` correspondint to splice site strength estimates in N different conditions (tissues, developmental time points)\n",
    "- Species vector of length `B` indicating the species for each sequence in the batch\n",
    "- Mappings of species indices to species names, and condition indices to condition names\n",
    "\n",
    "`B` is the batch size, `L` is the sequence length (consisting of core sequence `core_len` and `context_len` on both sides), and `N` is the number of conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "987952d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species 0: 1381 sequences\n",
      "  site type 0: 4060992\n",
      "  site type 1: 40795\n",
      "  site type 2: 41213\n",
      "Species 1: 1254 sequences\n",
      "  site type 0: 3687496\n",
      "  site type 1: 37054\n",
      "  site type 2: 37450\n",
      "Species 2: 1365 sequences\n",
      "  site type 0: 4013864\n",
      "  site type 1: 40367\n",
      "  site type 2: 40769\n"
     ]
    }
   ],
   "source": [
    "# Simulate small dataset\n",
    "B = 4000\n",
    "L = 3000\n",
    "context_len = 500\n",
    "core_len = L - 2 * context_len\n",
    "N = 5\n",
    "\n",
    "# Simulate random sequence input\n",
    "sequences = np.random.randint(0, 2, size=(B, L, 4)).astype(np.float32)\n",
    "\n",
    "# Simulate species assignment\n",
    "species = np.random.randint(0, 3, size = B).astype(np.int32)\n",
    "\n",
    "# Insert splice sites into random sequences\n",
    "def insert_splice_sites(sequences, donor_freq=0.01, acceptor_freq=0.01):\n",
    "    B = sequences.shape[0]\n",
    "    L = sequences.shape[1]\n",
    "    labels = np.zeros((B, L), dtype=np.int64)\n",
    "    for b in range(sequences.shape[0]):\n",
    "        donor_sites = np.random.randint(2, L, int(donor_freq * L))\n",
    "        acceptor_sites = np.random.randint(2, L, int(acceptor_freq * L))\n",
    "        for pos in donor_sites:\n",
    "            labels[b, pos] = 1\n",
    "            sequences[b, pos-2:pos, :] = [[0, 0, 1, 0],[0, 0, 0, 1]]  # 'GT' donor site\n",
    "        for pos in acceptor_sites:\n",
    "            labels[b, pos] = 2\n",
    "            sequences[b, pos-2:pos, :] = [[1, 0, 0, 0],[0, 0, 1, 0]]  # 'AG' acceptor site\n",
    "    return sequences, labels\n",
    "\n",
    "sequences, labels = insert_splice_sites(sequences)\n",
    "\n",
    "# Print number of sites per species\n",
    "for i in np.unique(species):\n",
    "    labels_i = labels[species == i]\n",
    "    print(f\"Species {i}: {labels_i.shape[0]} sequences\" )\n",
    "    for site_type in range(3):\n",
    "        print(f\"  site type {site_type}: {labels_i[labels_i == site_type].shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fce2f3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simulate SSE values distribution \n",
    "sse = np.random.beta(2, 0.5, size=(B, L, N)).astype(np.float32)\n",
    "# Set non-splice positions to zero SSE\n",
    "sse[labels == 0] = 0\n",
    "# Set a fraction of splice positions to zero SSE\n",
    "splice_positions = np.where(labels > 0)\n",
    "num_zero_sse = int(0.3 * len(splice_positions[0]))\n",
    "zero_sse_indices = np.random.choice(len(splice_positions[0]), num_zero_sse, replace=False)\n",
    "sse[splice_positions[0][zero_sse_indices], splice_positions[1][zero_sse_indices], np.random.randint(0, N, size=1)] = 0\n",
    "\n",
    "# Plot SSE distribution\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(sse[labels > 0].flatten(), bins=50)\n",
    "plt.xlabel('SSE value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac000b08",
   "metadata": {},
   "source": [
    "Split dataset into train (80%) and test (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0351d990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 2560\n",
      "Validation set size: 640\n",
      "Test set size: 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elek/miniforge3/envs/splicevo/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data loaders created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Train/test/validation split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Split into train+val and test (80/20)\n",
    "train_val_idx, test_idx = train_test_split(\n",
    "    np.arange(len(sequences)),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split train+val into train and validation (80/20 of train+val = 64/16 overall)\n",
    "train_idx, val_idx = train_test_split(\n",
    "    train_val_idx,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train set size: {len(train_idx)}\")\n",
    "print(f\"Validation set size: {len(val_idx)}\")\n",
    "print(f\"Test set size: {len(test_idx)}\")\n",
    "\n",
    "# Create train, validation, and test sets\n",
    "train_sequences, train_labels, train_sse, train_species = (\n",
    "    sequences[train_idx], labels[train_idx], sse[train_idx], species[train_idx]\n",
    ")\n",
    "val_sequences, val_labels, val_sse, val_species = (\n",
    "    sequences[val_idx], labels[val_idx], sse[val_idx], species[val_idx]\n",
    ")\n",
    "test_sequences, test_labels, test_sse, test_species = (\n",
    "    sequences[test_idx], labels[test_idx], sse[test_idx], species[test_idx]\n",
    ")\n",
    "\n",
    "# Create datasets\n",
    "from splicevo.training import SpliceDataset\n",
    "\n",
    "train_dataset = SpliceDataset(train_sequences, train_labels, train_sse, train_species)\n",
    "val_dataset = SpliceDataset(val_sequences, val_labels, val_sse, val_species)\n",
    "test_dataset = SpliceDataset(test_sequences, test_labels, test_sse, test_species)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"\\nData loaders created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e954160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 75624 donors, 76434 acceptors\n",
      "Validation set: 18938 donors, 19116 acceptors\n",
      "Test set: 23654 donors, 23882 acceptors\n"
     ]
    }
   ],
   "source": [
    "# Count splice sites in each set\n",
    "def count_splice_sites(labels):\n",
    "    donor_count = np.sum(labels == 1)\n",
    "    acceptor_count = np.sum(labels == 2)\n",
    "    return donor_count, acceptor_count\n",
    "train_donors, train_acceptors = count_splice_sites(train_labels)\n",
    "val_donors, val_acceptors = count_splice_sites(val_labels)\n",
    "test_donors, test_acceptors = count_splice_sites(test_labels)\n",
    "print(f\"Train set: {train_donors} donors, {train_acceptors} acceptors\")\n",
    "print(f\"Validation set: {val_donors} donors, {val_acceptors} acceptors\")\n",
    "print(f\"Test set: {test_donors} donors, {test_acceptors} acceptors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2742c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot SSE distribution for splice sites in each set\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(train_sse[train_labels > 0].flatten(), bins=50)\n",
    "plt.title('Train Set SSE Distribution')\n",
    "plt.xlabel('SSE value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(val_sse[val_labels > 0].flatten(), bins=50)\n",
    "plt.title('Validation Set SSE Distribution')\n",
    "plt.xlabel('SSE value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(test_sse[test_labels > 0].flatten(), bins=50)\n",
    "plt.title('Test Set SSE Distribution')\n",
    "plt.xlabel('SSE value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abf4578",
   "metadata": {},
   "source": [
    "## Train Splicevo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc7167bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized:\n",
      "  Encoder: Conv blocks with multi-scale fusion\n",
      "  Transformer: 8 attention heads\n",
      "  Output heads: Splice classification + SSE prediction\n"
     ]
    }
   ],
   "source": [
    "from splicevo.model import SplicevoModel\n",
    "from splicevo.training import SpliceTrainer, SpliceDataset\n",
    "import torch\n",
    "\n",
    "# Model configuration\n",
    "model_config = {\n",
    "    'embed_dim': 128,\n",
    "    'num_resblocks': 16,\n",
    "    'dilation_strategy': 'alternating',\n",
    "    'alternate': 4,\n",
    "    'num_classes': 3,\n",
    "    'n_conditions': N,\n",
    "    'context_len': context_len,\n",
    "    'num_heads': 8,\n",
    "    'dropout': 0.3,\n",
    "    'usage_loss_type': 'weighted_mse',\n",
    "    'n_species': len(np.unique(species))\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "model = SplicevoModel(**model_config)\n",
    "print(\"Model initialized:\")\n",
    "print(f\"  Encoder: Conv blocks with multi-scale fusion\")\n",
    "print(f\"  Transformer: {model_config['num_heads']} attention heads\")\n",
    "print(f\"  Output heads: Splice classification + SSE prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9bce7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "training_config = {\n",
    "    'learning_rate': 1.0e-3,\n",
    "    'weight_decay': 1.0e-3,\n",
    "    'num_epochs': 100,\n",
    "    'splice_weight': 0.5,\n",
    "    'usage_weight': 0.5,\n",
    "    'weighted_mse_extreme_low': 0.1,\n",
    "    'weighted_mse_extreme_high': 0.9,\n",
    "    'weighted_mse_extreme_weight': 5.0,\n",
    "    'early_stopping_patience': 5\n",
    "}\n",
    "\n",
    "# Create trainer\n",
    "trainer = SpliceTrainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    learning_rate=training_config['learning_rate'],\n",
    "    weight_decay=training_config['weight_decay'],\n",
    "    splice_weight=training_config['splice_weight'],\n",
    "    usage_weight=training_config['usage_weight'],\n",
    "    weighted_mse_extreme_low=training_config['weighted_mse_extreme_low'],\n",
    "    weighted_mse_extreme_high=training_config['weighted_mse_extreme_high'],\n",
    "    weighted_mse_extreme_weight=training_config['weighted_mse_extreme_weight'],\n",
    "    usage_loss_type=model_config['usage_loss_type'],\n",
    ")\n",
    "\n",
    "print(\"Trainer created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57645387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elek/miniforge3/envs/splicevo/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First epoch completed in 8.7s\n",
      "Estimated total training time: 0:14:25\n",
      "Estimated completion: 2026-01-09 17:05:30\n",
      "\n",
      "Epoch 1/100 (8.7s) - Train Loss: 0.4278 (Splice: 0.1911, Usage: 0.6646) - Val Loss: 0.1571 (Splice: 0.0965, Usage: 0.2177)\n",
      "Epoch 2/100 (7.9s) - Train Loss: 0.1631 (Splice: 0.0605, Usage: 0.2658) - Val Loss: 0.1250 (Splice: 0.0351, Usage: 0.2149) - ETA: 17:04:44\n",
      "Epoch 3/100 (7.9s) - Train Loss: 0.1347 (Splice: 0.0336, Usage: 0.2358) - Val Loss: 0.1222 (Splice: 0.0323, Usage: 0.2121) - ETA: 17:04:32\n",
      "Epoch 4/100 (7.9s) - Train Loss: 0.1320 (Splice: 0.0328, Usage: 0.2312) - Val Loss: 0.1225 (Splice: 0.0322, Usage: 0.2129) - ETA: 17:04:26\n",
      "Epoch 5/100 (7.9s) - Train Loss: 0.1303 (Splice: 0.0326, Usage: 0.2281) - Val Loss: 0.1221 (Splice: 0.0324, Usage: 0.2118) - ETA: 17:04:22\n",
      "Epoch 6/100 (7.9s) - Train Loss: 0.1288 (Splice: 0.0323, Usage: 0.2253) - Val Loss: 0.1222 (Splice: 0.0321, Usage: 0.2122) - ETA: 17:04:18\n",
      "Epoch 7/100 (7.9s) - Train Loss: 0.1281 (Splice: 0.0321, Usage: 0.2241) - Val Loss: 0.1223 (Splice: 0.0320, Usage: 0.2126) - ETA: 17:04:16\n",
      "Epoch 8/100 (7.8s) - Train Loss: 0.1273 (Splice: 0.0313, Usage: 0.2233) - Val Loss: 0.1222 (Splice: 0.0297, Usage: 0.2146) - ETA: 17:04:14\n",
      "Epoch 9/100 (7.8s) - Train Loss: 0.1253 (Splice: 0.0272, Usage: 0.2233) - Val Loss: 0.1191 (Splice: 0.0249, Usage: 0.2132) - ETA: 17:04:12\n",
      "Epoch 10/100 (7.9s) - Train Loss: 0.1236 (Splice: 0.0231, Usage: 0.2240) - Val Loss: 0.1175 (Splice: 0.0220, Usage: 0.2129) - ETA: 17:04:12\n",
      "Epoch 11/100 (7.8s) - Train Loss: 0.1220 (Splice: 0.0208, Usage: 0.2231) - Val Loss: 0.1163 (Splice: 0.0202, Usage: 0.2123) - ETA: 17:04:10\n",
      "Epoch 12/100 (7.8s) - Train Loss: 0.1210 (Splice: 0.0199, Usage: 0.2220) - Val Loss: 0.1158 (Splice: 0.0196, Usage: 0.2119) - ETA: 17:04:09\n",
      "Epoch 13/100 (7.8s) - Train Loss: 0.1200 (Splice: 0.0194, Usage: 0.2205) - Val Loss: 0.1159 (Splice: 0.0193, Usage: 0.2125) - ETA: 17:04:08\n",
      "Epoch 14/100 (7.9s) - Train Loss: 0.1194 (Splice: 0.0191, Usage: 0.2197) - Val Loss: 0.1159 (Splice: 0.0191, Usage: 0.2128) - ETA: 17:04:08\n",
      "Epoch 15/100 (7.8s) - Train Loss: 0.1194 (Splice: 0.0190, Usage: 0.2197) - Val Loss: 0.1159 (Splice: 0.0192, Usage: 0.2127) - ETA: 17:04:08\n",
      "Epoch 16/100 (7.8s) - Train Loss: 0.1191 (Splice: 0.0188, Usage: 0.2193) - Val Loss: 0.1157 (Splice: 0.0192, Usage: 0.2121) - ETA: 17:04:07\n",
      "Epoch 17/100 (7.8s) - Train Loss: 0.1187 (Splice: 0.0187, Usage: 0.2187) - Val Loss: 0.1154 (Splice: 0.0187, Usage: 0.2122) - ETA: 17:04:07\n",
      "Epoch 18/100 (7.8s) - Train Loss: 0.1187 (Splice: 0.0187, Usage: 0.2187) - Val Loss: 0.1157 (Splice: 0.0188, Usage: 0.2126) - ETA: 17:04:07\n",
      "Epoch 19/100 (7.8s) - Train Loss: 0.1185 (Splice: 0.0185, Usage: 0.2184) - Val Loss: 0.1162 (Splice: 0.0192, Usage: 0.2132) - ETA: 17:04:06\n",
      "Epoch 20/100 (7.8s) - Train Loss: 0.1184 (Splice: 0.0186, Usage: 0.2182) - Val Loss: 0.1153 (Splice: 0.0189, Usage: 0.2118) - ETA: 17:04:06\n",
      "Epoch 21/100 (7.8s) - Train Loss: 0.1185 (Splice: 0.0185, Usage: 0.2184) - Val Loss: 0.1176 (Splice: 0.0192, Usage: 0.2160) - ETA: 17:04:06\n",
      "Epoch 22/100 (7.8s) - Train Loss: 0.1180 (Splice: 0.0187, Usage: 0.2174) - Val Loss: 0.1158 (Splice: 0.0190, Usage: 0.2126) - ETA: 17:04:05\n",
      "Epoch 23/100 (7.9s) - Train Loss: 0.1185 (Splice: 0.0188, Usage: 0.2182) - Val Loss: 0.1168 (Splice: 0.0196, Usage: 0.2139) - ETA: 17:04:05\n",
      "Epoch 24/100 (7.9s) - Train Loss: 0.1173 (Splice: 0.0188, Usage: 0.2159) - Val Loss: 0.1172 (Splice: 0.0193, Usage: 0.2151) - ETA: 17:04:05\n",
      "Epoch 25/100 (7.9s) - Train Loss: 0.1168 (Splice: 0.0190, Usage: 0.2146) - Val Loss: 0.1168 (Splice: 0.0189, Usage: 0.2147) - ETA: 17:04:05\n",
      "Early stopping after 25 epochs\n",
      "\n",
      "Training Summary:\n",
      "  Total epochs: 25\n",
      "  Total time: 0:03:17\n",
      "  Avg epoch time: 7.9s\n",
      "  Best val loss: 0.1153\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "print(\"Training model...\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "history = trainer.train(\n",
    "    n_epochs=training_config['num_epochs'],\n",
    "    early_stopping_patience=training_config['early_stopping_patience']\n",
    ")\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36923850",
   "metadata": {},
   "source": [
    "# Predict with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "442ca20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SplicevoModel(\n",
       "  (encoder): EncoderModule(\n",
       "    (initial_conv): Conv1d(4, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "    (input_relu): ReLU(inplace=True)\n",
       "    (resblocks): ModuleList(\n",
       "      (0-3): 4 x ResBlock(\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "      (4-7): 4 x ResBlock(\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
       "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "      (8-11): 4 x ResBlock(\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(16,), dilation=(4,))\n",
       "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "      (12-15): 4 x ResBlock(\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(32,), dilation=(8,))\n",
       "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "    )\n",
       "    (initial_skip_proj): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "    (group_skip_projections): ModuleList(\n",
       "      (0-3): 4 x Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (fusion_reduce): Conv1d(640, 128, kernel_size=(1,), stride=(1,))\n",
       "    (fusion_activation): ReLU(inplace=True)\n",
       "    (fusion_expand): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "    (output_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (transformer): TransformerModule(\n",
       "    (attention): MultiHeadAttention(\n",
       "      (query_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (key_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (value_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (attn_dropout): Dropout(p=0.3, inplace=False)\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (splice_classifiers): ModuleDict(\n",
       "    (species_0): Conv1d(128, 3, kernel_size=(1,), stride=(1,))\n",
       "    (species_1): Conv1d(128, 3, kernel_size=(1,), stride=(1,))\n",
       "    (species_2): Conv1d(128, 3, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (usage_predictors): ModuleDict(\n",
       "    (species_0): Conv1d(128, 5, kernel_size=(1,), stride=(1,))\n",
       "    (species_1): Conv1d(128, 5, kernel_size=(1,), stride=(1,))\n",
       "    (species_2): Conv1d(128, 5, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set model in evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0dfb7f",
   "metadata": {},
   "source": [
    "Calculate predictions on the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd7f2c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 10/50 batches\n",
      "  Processed 20/50 batches\n",
      "  Processed 30/50 batches\n",
      "  Processed 40/50 batches\n",
      "  Processed 50/50 batches\n",
      "\n",
      "Predictions collected:\n",
      "  Splice predictions shape: (800, 2000)\n",
      "  Splice ground truth shape: (800, 3000)\n",
      "  Usage predictions shape: (800, 2000, 5)\n",
      "  Usage ground truth shape: (800, 3000, 5)\n"
     ]
    }
   ],
   "source": [
    "all_splice_preds = []\n",
    "all_splice_true = []\n",
    "all_usage_preds = []\n",
    "all_usage_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_loader):\n",
    "        sequences = batch['sequences'].to(device)\n",
    "        splice_labels = batch['splice_labels'].to(device)\n",
    "        usage_targets = batch['usage_targets'].to(device)\n",
    "        species_ids = batch['species_id'].to(device) if 'species_id' in batch else None\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(sequences, species_ids=species_ids)\n",
    "        \n",
    "        # Get predictions\n",
    "        splice_logits = outputs['splice_logits']  # (batch, central_len, num_classes)\n",
    "        splice_preds = torch.argmax(splice_logits, dim=-1)  # (batch, central_len)\n",
    "        \n",
    "        usage_preds = torch.sigmoid(outputs['usage_predictions'])  # (batch, central_len, n_conditions)\n",
    "        \n",
    "        # Move to CPU and convert to numpy\n",
    "        all_splice_preds.append(splice_preds.cpu().numpy())\n",
    "        all_splice_true.append(splice_labels.cpu().numpy())\n",
    "        all_usage_preds.append(usage_preds.cpu().numpy())\n",
    "        all_usage_true.append(usage_targets.cpu().numpy())\n",
    "        \n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"  Processed {batch_idx + 1}/{len(test_loader)} batches\")\n",
    "\n",
    "# Concatenate all predictions\n",
    "splice_preds_all = np.concatenate(all_splice_preds)  # (n_test, central_len)\n",
    "splice_true_all = np.concatenate(all_splice_true)    # (n_test, central_len)\n",
    "usage_preds_all = np.concatenate(all_usage_preds)    # (n_test, central_len, n_conditions)\n",
    "usage_true_all = np.concatenate(all_usage_true)      # (n_test, central_len, n_conditions)\n",
    "\n",
    "print(f\"\\nPredictions collected:\")\n",
    "print(f\"  Splice predictions shape: {splice_preds_all.shape}\")\n",
    "print(f\"  Splice ground truth shape: {splice_true_all.shape}\")\n",
    "print(f\"  Usage predictions shape: {usage_preds_all.shape}\")\n",
    "print(f\"  Usage ground truth shape: {usage_true_all.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b454d69",
   "metadata": {},
   "source": [
    "Compute evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6166829e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splice site classification:\n",
      "  Overall accuracy: 0.9914\n",
      "  Not splice      - Precision: 0.9990, Recall: 0.9922, F1: 0.9956\n",
      "  Donor           - Precision: 0.7116, Recall: 0.9391, F1: 0.8097\n",
      "  Acceptor        - Precision: 0.7111, Recall: 0.9643, F1: 0.8186\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Flatten for overall accuracy\n",
    "splice_preds_flat = splice_preds_all.flatten()\n",
    "splice_true_flat = splice_true_all[:, context_len:-context_len].flatten()\n",
    "\n",
    "accuracy = accuracy_score(splice_true_flat, splice_preds_flat)\n",
    "print(f\"\\nSplice site classification:\")\n",
    "print(f\"  Overall accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Per-class metrics\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    splice_true_flat, splice_preds_flat, \n",
    "    labels=[0, 1, 2],\n",
    "    zero_division=0\n",
    ")\n",
    "class_names = ['Not splice', 'Donor', 'Acceptor']\n",
    "for i, name in enumerate(class_names):\n",
    "    print(f\"  {name:15} - Precision: {precision[i]:.4f}, Recall: {recall[i]:.4f}, F1: {f1[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24f130c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage prediction:\n",
      "  Mean squared error: 0.459176\n",
      "  Condition 0 MSE: 0.526503\n",
      "  Condition 1 MSE: 0.522153\n",
      "  Condition 2 MSE: 0.202671\n",
      "  Condition 3 MSE: 0.520918\n",
      "  Condition 4 MSE: 0.523636\n"
     ]
    }
   ],
   "source": [
    "# Usage prediction metrics (MSE)\n",
    "usage_true_all = usage_true_all[:, context_len:-context_len, :] \n",
    "usage_mse = np.mean((usage_preds_all - usage_true_all) ** 2)\n",
    "print(f\"\\nUsage prediction:\")\n",
    "print(f\"  Mean squared error: {usage_mse:.6f}\")\n",
    "\n",
    "# Per-condition MSE\n",
    "for cond_idx in range(usage_preds_all.shape[-1]):\n",
    "    cond_mse = np.mean((usage_preds_all[..., cond_idx] - usage_true_all[..., cond_idx]) ** 2)\n",
    "    print(f\"  Condition {cond_idx} MSE: {cond_mse:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "splicevo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
