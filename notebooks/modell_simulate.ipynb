{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4bcf21b",
   "metadata": {},
   "source": [
    "# Train small Splicevo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c74981a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9090ebdc",
   "metadata": {},
   "source": [
    "## Simulate small dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d65ddbf",
   "metadata": {},
   "source": [
    "To train a Splicevo model, we need the following data:\n",
    "\n",
    "- Input DNA sequences of shape `B, L, 4` (one-hot encoded)\n",
    "- Labels of shape `B, L` corresponding to splice site annotations (0=not a splice site, 1=splice donor, 2=splice acceptor)\n",
    "- SSE values of shape `B, L, N` correspondint to splice site strength estimates in N different conditions (tissues, developmental time points)\n",
    "- Species vector of length `B` indicating the species for each sequence in the batch\n",
    "- Mappings of species indices to species names, and condition indices to condition names\n",
    "\n",
    "`B` is the batch size, `L` is the sequence length (consisting of core sequence `core_len` and `context_len` on both sides), and `N` is the number of conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "987952d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species 0: 1355 sequences\n",
      "  site type 0: 3984482\n",
      "  site type 1: 40040\n",
      "  site type 2: 40478\n",
      "Species 1: 1311 sequences\n",
      "  site type 0: 3855118\n",
      "  site type 1: 38741\n",
      "  site type 2: 39141\n",
      "Species 2: 1334 sequences\n",
      "  site type 0: 3922759\n",
      "  site type 1: 39405\n",
      "  site type 2: 39836\n"
     ]
    }
   ],
   "source": [
    "# Simulate small dataset\n",
    "B = 4000\n",
    "L = 3000\n",
    "context_len = 500\n",
    "core_len = L - 2 * context_len\n",
    "N = 5\n",
    "\n",
    "# Simulate random sequence input\n",
    "sequences = np.random.randint(0, 2, size=(B, L, 4)).astype(np.float32)\n",
    "\n",
    "# Simulate species assignment\n",
    "species = np.random.randint(0, 3, size = B).astype(np.int32)\n",
    "\n",
    "# Insert splice sites into random sequences\n",
    "def insert_splice_sites(sequences, donor_freq=0.01, acceptor_freq=0.01):\n",
    "    B = sequences.shape[0]\n",
    "    L = sequences.shape[1]\n",
    "    labels = np.zeros((B, L), dtype=np.int64)\n",
    "    for b in range(sequences.shape[0]):\n",
    "        donor_sites = np.random.randint(2, L, int(donor_freq * L))\n",
    "        acceptor_sites = np.random.randint(2, L, int(acceptor_freq * L))\n",
    "        for pos in donor_sites:\n",
    "            labels[b, pos] = 1\n",
    "            sequences[b, pos-2:pos, :] = [[0, 0, 1, 0],[0, 0, 0, 1]]  # 'GT' donor site\n",
    "        for pos in acceptor_sites:\n",
    "            labels[b, pos] = 2\n",
    "            sequences[b, pos-2:pos, :] = [[1, 0, 0, 0],[0, 0, 1, 0]]  # 'AG' acceptor site\n",
    "    return sequences, labels\n",
    "\n",
    "sequences, labels = insert_splice_sites(sequences)\n",
    "\n",
    "# Print number of sites per species\n",
    "for i in np.unique(species):\n",
    "    labels_i = labels[species == i]\n",
    "    print(f\"Species {i}: {labels_i.shape[0]} sequences\" )\n",
    "    for site_type in range(3):\n",
    "        print(f\"  site type {site_type}: {labels_i[labels_i == site_type].shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fce2f3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simulate SSE values distribution \n",
    "sse = np.random.beta(2, 0.5, size=(B, L, N)).astype(np.float32)\n",
    "# Set non-splice positions to zero SSE\n",
    "sse[labels == 0] = 0\n",
    "# Set a fraction of splice positions to zero SSE\n",
    "splice_positions = np.where(labels > 0)\n",
    "num_zero_sse = int(0.3 * len(splice_positions[0]))\n",
    "zero_sse_indices = np.random.choice(len(splice_positions[0]), num_zero_sse, replace=False)\n",
    "sse[splice_positions[0][zero_sse_indices], splice_positions[1][zero_sse_indices], np.random.randint(0, N, size=1)] = 0\n",
    "\n",
    "# Plot SSE distribution\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(sse[labels > 0].flatten(), bins=50)\n",
    "plt.xlabel('SSE value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac000b08",
   "metadata": {},
   "source": [
    "Split dataset into train (80%) and test (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0351d990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 2560\n",
      "Validation set size: 640\n",
      "Test set size: 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elek/miniforge3/envs/splicevo/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data loaders created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Train/test/validation split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Split into train+val and test (80/20)\n",
    "train_val_idx, test_idx = train_test_split(\n",
    "    np.arange(len(sequences)),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split train+val into train and validation (80/20 of train+val = 64/16 overall)\n",
    "train_idx, val_idx = train_test_split(\n",
    "    train_val_idx,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train set size: {len(train_idx)}\")\n",
    "print(f\"Validation set size: {len(val_idx)}\")\n",
    "print(f\"Test set size: {len(test_idx)}\")\n",
    "\n",
    "# Create train, validation, and test sets\n",
    "train_sequences, train_labels, train_sse, train_species = (\n",
    "    sequences[train_idx], labels[train_idx], sse[train_idx], species[train_idx]\n",
    ")\n",
    "val_sequences, val_labels, val_sse, val_species = (\n",
    "    sequences[val_idx], labels[val_idx], sse[val_idx], species[val_idx]\n",
    ")\n",
    "test_sequences, test_labels, test_sse, test_species = (\n",
    "    sequences[test_idx], labels[test_idx], sse[test_idx], species[test_idx]\n",
    ")\n",
    "\n",
    "# Create datasets\n",
    "from splicevo.training import SpliceDataset\n",
    "\n",
    "train_dataset = SpliceDataset(train_sequences, train_labels, train_sse, train_species)\n",
    "val_dataset = SpliceDataset(val_sequences, val_labels, val_sse, val_species)\n",
    "test_dataset = SpliceDataset(test_sequences, test_labels, test_sse, test_species)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"\\nData loaders created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e954160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 75690 donors, 76454 acceptors\n",
      "Validation set: 18891 donors, 19099 acceptors\n",
      "Test set: 23605 donors, 23902 acceptors\n"
     ]
    }
   ],
   "source": [
    "# Count splice sites in each set\n",
    "def count_splice_sites(labels):\n",
    "    donor_count = np.sum(labels == 1)\n",
    "    acceptor_count = np.sum(labels == 2)\n",
    "    return donor_count, acceptor_count\n",
    "train_donors, train_acceptors = count_splice_sites(train_labels)\n",
    "val_donors, val_acceptors = count_splice_sites(val_labels)\n",
    "test_donors, test_acceptors = count_splice_sites(test_labels)\n",
    "print(f\"Train set: {train_donors} donors, {train_acceptors} acceptors\")\n",
    "print(f\"Validation set: {val_donors} donors, {val_acceptors} acceptors\")\n",
    "print(f\"Test set: {test_donors} donors, {test_acceptors} acceptors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2742c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot SSE distribution for splice sites in each set\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(train_sse[train_labels > 0].flatten(), bins=50)\n",
    "plt.title('Train Set SSE Distribution')\n",
    "plt.xlabel('SSE value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(val_sse[val_labels > 0].flatten(), bins=50)\n",
    "plt.title('Validation Set SSE Distribution')\n",
    "plt.xlabel('SSE value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(test_sse[test_labels > 0].flatten(), bins=50)\n",
    "plt.title('Test Set SSE Distribution')\n",
    "plt.xlabel('SSE value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abf4578",
   "metadata": {},
   "source": [
    "## Train Splicevo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc7167bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized:\n",
      "  Encoder: Conv blocks with multi-scale fusion\n",
      "  Transformer: 8 attention heads\n",
      "  Output heads: Splice classification + SSE prediction\n"
     ]
    }
   ],
   "source": [
    "from splicevo.model import SplicevoModel\n",
    "from splicevo.training import SpliceTrainer, SpliceDataset\n",
    "import torch\n",
    "\n",
    "# Model configuration\n",
    "model_config = {\n",
    "    'embed_dim': 128,\n",
    "    'num_resblocks': 16,\n",
    "    'dilation_strategy': 'alternating',\n",
    "    'alternate': 4,\n",
    "    'num_classes': 3,\n",
    "    'n_conditions': N,\n",
    "    'context_len': context_len,\n",
    "    'num_heads': 8,\n",
    "    'dropout': 0.3,\n",
    "    'usage_loss_type': 'weighted_mse',\n",
    "    'n_species': len(np.unique(species))\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "model = SplicevoModel(**model_config)\n",
    "print(\"Model initialized:\")\n",
    "print(f\"  Encoder: Conv blocks with multi-scale fusion\")\n",
    "print(f\"  Transformer: {model_config['num_heads']} attention heads\")\n",
    "print(f\"  Output heads: Splice classification + SSE prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9bce7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "training_config = {\n",
    "    'learning_rate': 1.0e-3,\n",
    "    'weight_decay': 1.0e-3,\n",
    "    'num_epochs': 100,\n",
    "    'splice_weight': 0.5,\n",
    "    'usage_weight': 0.5,\n",
    "    'weighted_mse_extreme_low': 0.1,\n",
    "    'weighted_mse_extreme_high': 0.9,\n",
    "    'weighted_mse_extreme_weight': 5.0,\n",
    "    'early_stopping_patience': 5\n",
    "}\n",
    "\n",
    "# Create trainer\n",
    "trainer = SpliceTrainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    learning_rate=training_config['learning_rate'],\n",
    "    weight_decay=training_config['weight_decay'],\n",
    "    splice_weight=training_config['splice_weight'],\n",
    "    usage_weight=training_config['usage_weight'],\n",
    "    weighted_mse_extreme_low=training_config['weighted_mse_extreme_low'],\n",
    "    weighted_mse_extreme_high=training_config['weighted_mse_extreme_high'],\n",
    "    weighted_mse_extreme_weight=training_config['weighted_mse_extreme_weight'],\n",
    "    usage_loss_type=model_config['usage_loss_type'],\n",
    ")\n",
    "\n",
    "print(\"Trainer created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57645387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elek/miniforge3/envs/splicevo/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First epoch completed in 14.5s\n",
      "Estimated total training time: 0:24:11\n",
      "Estimated completion: 2026-01-09 13:30:10\n",
      "\n",
      "Epoch 1/100 (14.5s) - Train Loss: 0.3704 (Splice: 0.1600, Usage: 0.5808) - Val Loss: 0.1580 (Splice: 0.1036, Usage: 0.2124)\n",
      "Epoch 2/100 (13.7s) - Train Loss: 0.1633 (Splice: 0.0634, Usage: 0.2633) - Val Loss: 0.1231 (Splice: 0.0345, Usage: 0.2117) - ETA: 13:29:15\n",
      "Epoch 3/100 (13.7s) - Train Loss: 0.1345 (Splice: 0.0336, Usage: 0.2353) - Val Loss: 0.1230 (Splice: 0.0327, Usage: 0.2133) - ETA: 13:29:00\n",
      "Epoch 4/100 (13.7s) - Train Loss: 0.1310 (Splice: 0.0327, Usage: 0.2292) - Val Loss: 0.1219 (Splice: 0.0322, Usage: 0.2116) - ETA: 13:28:54\n",
      "Epoch 5/100 (14.1s) - Train Loss: 0.1301 (Splice: 0.0324, Usage: 0.2279) - Val Loss: 0.1211 (Splice: 0.0322, Usage: 0.2100) - ETA: 13:28:57\n",
      "Epoch 6/100 (16.3s) - Train Loss: 0.1283 (Splice: 0.0322, Usage: 0.2243) - Val Loss: 0.1212 (Splice: 0.0321, Usage: 0.2103) - ETA: 13:29:36\n",
      "Epoch 7/100 (16.7s) - Train Loss: 0.1277 (Splice: 0.0320, Usage: 0.2233) - Val Loss: 0.1252 (Splice: 0.0317, Usage: 0.2187) - ETA: 13:30:10\n",
      "Epoch 8/100 (16.8s) - Train Loss: 0.1271 (Splice: 0.0306, Usage: 0.2235) - Val Loss: 0.1203 (Splice: 0.0286, Usage: 0.2120) - ETA: 13:30:37\n",
      "Epoch 9/100 (16.8s) - Train Loss: 0.1244 (Splice: 0.0254, Usage: 0.2233) - Val Loss: 0.1166 (Splice: 0.0228, Usage: 0.2104) - ETA: 13:30:58\n",
      "Epoch 10/100 (15.0s) - Train Loss: 0.1221 (Splice: 0.0216, Usage: 0.2226) - Val Loss: 0.1153 (Splice: 0.0206, Usage: 0.2101) - ETA: 13:30:57\n",
      "Epoch 11/100 (13.7s) - Train Loss: 0.1208 (Splice: 0.0203, Usage: 0.2213) - Val Loss: 0.1152 (Splice: 0.0195, Usage: 0.2109) - ETA: 13:30:44\n",
      "Epoch 12/100 (13.7s) - Train Loss: 0.1202 (Splice: 0.0196, Usage: 0.2207) - Val Loss: 0.1148 (Splice: 0.0189, Usage: 0.2108) - ETA: 13:30:33\n",
      "Epoch 13/100 (13.7s) - Train Loss: 0.1200 (Splice: 0.0193, Usage: 0.2207) - Val Loss: 0.1146 (Splice: 0.0189, Usage: 0.2103) - ETA: 13:30:24\n",
      "Epoch 14/100 (13.7s) - Train Loss: 0.1192 (Splice: 0.0191, Usage: 0.2193) - Val Loss: 0.1148 (Splice: 0.0189, Usage: 0.2107) - ETA: 13:30:16\n",
      "Epoch 15/100 (14.0s) - Train Loss: 0.1188 (Splice: 0.0189, Usage: 0.2188) - Val Loss: 0.1152 (Splice: 0.0189, Usage: 0.2115) - ETA: 13:30:11\n",
      "Epoch 16/100 (14.0s) - Train Loss: 0.1190 (Splice: 0.0189, Usage: 0.2192) - Val Loss: 0.1148 (Splice: 0.0190, Usage: 0.2106) - ETA: 13:30:07\n",
      "Epoch 17/100 (13.7s) - Train Loss: 0.1184 (Splice: 0.0189, Usage: 0.2180) - Val Loss: 0.1151 (Splice: 0.0193, Usage: 0.2108) - ETA: 13:30:02\n",
      "Epoch 18/100 (14.0s) - Train Loss: 0.1184 (Splice: 0.0189, Usage: 0.2179) - Val Loss: 0.1146 (Splice: 0.0189, Usage: 0.2102) - ETA: 13:29:59\n",
      "Epoch 19/100 (14.0s) - Train Loss: 0.1181 (Splice: 0.0190, Usage: 0.2173) - Val Loss: 0.1152 (Splice: 0.0190, Usage: 0.2114) - ETA: 13:29:56\n",
      "Epoch 20/100 (14.0s) - Train Loss: 0.1180 (Splice: 0.0190, Usage: 0.2170) - Val Loss: 0.1150 (Splice: 0.0191, Usage: 0.2109) - ETA: 13:29:53\n",
      "Epoch 21/100 (14.0s) - Train Loss: 0.1179 (Splice: 0.0190, Usage: 0.2167) - Val Loss: 0.1160 (Splice: 0.0190, Usage: 0.2131) - ETA: 13:29:50\n",
      "Epoch 22/100 (14.0s) - Train Loss: 0.1177 (Splice: 0.0192, Usage: 0.2162) - Val Loss: 0.1152 (Splice: 0.0191, Usage: 0.2113) - ETA: 13:29:48\n",
      "Epoch 23/100 (13.7s) - Train Loss: 0.1168 (Splice: 0.0190, Usage: 0.2146) - Val Loss: 0.1155 (Splice: 0.0191, Usage: 0.2120) - ETA: 13:29:45\n",
      "Early stopping after 23 epochs\n",
      "\n",
      "Training Summary:\n",
      "  Total epochs: 23\n",
      "  Total time: 0:05:31\n",
      "  Avg epoch time: 14.4s\n",
      "  Best val loss: 0.1146\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "print(\"Training model...\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "history = trainer.train(\n",
    "    n_epochs=training_config['num_epochs'],\n",
    "    early_stopping_patience=training_config['early_stopping_patience']\n",
    ")\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36923850",
   "metadata": {},
   "source": [
    "# Predict with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "442ca20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SplicevoModel(\n",
       "  (encoder): EncoderModule(\n",
       "    (initial_conv): Conv1d(4, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "    (input_relu): ReLU(inplace=True)\n",
       "    (resblocks): ModuleList(\n",
       "      (0-3): 4 x ResBlock(\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "      (4-7): 4 x ResBlock(\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
       "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "      (8-11): 4 x ResBlock(\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(16,), dilation=(4,))\n",
       "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "      (12-15): 4 x ResBlock(\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(32,), dilation=(8,))\n",
       "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "    )\n",
       "    (initial_skip_proj): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "    (group_skip_projections): ModuleList(\n",
       "      (0-3): 4 x Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (fusion_reduce): Conv1d(640, 128, kernel_size=(1,), stride=(1,))\n",
       "    (fusion_activation): ReLU(inplace=True)\n",
       "    (fusion_expand): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "    (output_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (transformer): TransformerModule(\n",
       "    (attention): MultiHeadAttention(\n",
       "      (query_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (key_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (value_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (attn_dropout): Dropout(p=0.3, inplace=False)\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (splice_classifiers): ModuleDict(\n",
       "    (species_0): Conv1d(128, 3, kernel_size=(1,), stride=(1,))\n",
       "    (species_1): Conv1d(128, 3, kernel_size=(1,), stride=(1,))\n",
       "    (species_2): Conv1d(128, 3, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (usage_predictors): ModuleDict(\n",
       "    (species_0): Conv1d(128, 5, kernel_size=(1,), stride=(1,))\n",
       "    (species_1): Conv1d(128, 5, kernel_size=(1,), stride=(1,))\n",
       "    (species_2): Conv1d(128, 5, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set model in evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0dfb7f",
   "metadata": {},
   "source": [
    "Calculate predictions on the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd7f2c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 10/50 batches\n",
      "  Processed 20/50 batches\n",
      "  Processed 30/50 batches\n",
      "  Processed 40/50 batches\n",
      "  Processed 50/50 batches\n",
      "\n",
      "Predictions collected:\n",
      "  Splice predictions shape: (800, 2000)\n",
      "  Splice ground truth shape: (800, 3000)\n",
      "  Usage predictions shape: (800, 2000, 5)\n",
      "  Usage ground truth shape: (800, 3000, 5)\n"
     ]
    }
   ],
   "source": [
    "all_splice_preds = []\n",
    "all_splice_true = []\n",
    "all_usage_preds = []\n",
    "all_usage_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_loader):\n",
    "        sequences = batch['sequences'].to(device)\n",
    "        splice_labels = batch['splice_labels'].to(device)\n",
    "        usage_targets = batch['usage_targets'].to(device)\n",
    "        species_ids = batch['species_id'].to(device) if 'species_id' in batch else None\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(sequences, species_ids=species_ids)\n",
    "        \n",
    "        # Get predictions\n",
    "        splice_logits = outputs['splice_logits']  # (batch, central_len, num_classes)\n",
    "        splice_preds = torch.argmax(splice_logits, dim=-1)  # (batch, central_len)\n",
    "        \n",
    "        usage_preds = torch.sigmoid(outputs['usage_predictions'])  # (batch, central_len, n_conditions)\n",
    "        \n",
    "        # Move to CPU and convert to numpy\n",
    "        all_splice_preds.append(splice_preds.cpu().numpy())\n",
    "        all_splice_true.append(splice_labels.cpu().numpy())\n",
    "        all_usage_preds.append(usage_preds.cpu().numpy())\n",
    "        all_usage_true.append(usage_targets.cpu().numpy())\n",
    "        \n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"  Processed {batch_idx + 1}/{len(test_loader)} batches\")\n",
    "\n",
    "# Concatenate all predictions\n",
    "splice_preds_all = np.concatenate(all_splice_preds)  # (n_test, central_len)\n",
    "splice_true_all = np.concatenate(all_splice_true)    # (n_test, central_len)\n",
    "usage_preds_all = np.concatenate(all_usage_preds)    # (n_test, central_len, n_conditions)\n",
    "usage_true_all = np.concatenate(all_usage_true)      # (n_test, central_len, n_conditions)\n",
    "\n",
    "print(f\"\\nPredictions collected:\")\n",
    "print(f\"  Splice predictions shape: {splice_preds_all.shape}\")\n",
    "print(f\"  Splice ground truth shape: {splice_true_all.shape}\")\n",
    "print(f\"  Usage predictions shape: {usage_preds_all.shape}\")\n",
    "print(f\"  Usage ground truth shape: {usage_true_all.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b454d69",
   "metadata": {},
   "source": [
    "Compute evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6166829e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splice site classification:\n",
      "  Overall accuracy: 0.9911\n",
      "  Not splice      - Precision: 0.9983, Recall: 0.9925, F1: 0.9954\n",
      "  Donor           - Precision: 0.7146, Recall: 0.9014, F1: 0.7972\n",
      "  Acceptor        - Precision: 0.7101, Recall: 0.9330, F1: 0.8064\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Flatten for overall accuracy\n",
    "splice_preds_flat = splice_preds_all.flatten()\n",
    "splice_true_flat = splice_true_all[:, context_len:-context_len].flatten()\n",
    "\n",
    "accuracy = accuracy_score(splice_true_flat, splice_preds_flat)\n",
    "print(f\"\\nSplice site classification:\")\n",
    "print(f\"  Overall accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Per-class metrics\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    splice_true_flat, splice_preds_flat, \n",
    "    labels=[0, 1, 2],\n",
    "    zero_division=0\n",
    ")\n",
    "class_names = ['Not splice', 'Donor', 'Acceptor']\n",
    "for i, name in enumerate(class_names):\n",
    "    print(f\"  {name:15} - Precision: {precision[i]:.4f}, Recall: {recall[i]:.4f}, F1: {f1[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24f130c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage prediction:\n",
      "  Mean squared error: 0.476746\n",
      "  Condition 0 MSE: 0.542514\n",
      "  Condition 1 MSE: 0.548451\n",
      "  Condition 2 MSE: 0.543828\n",
      "  Condition 3 MSE: 0.212343\n",
      "  Condition 4 MSE: 0.536596\n"
     ]
    }
   ],
   "source": [
    "# Usage prediction metrics (MSE)\n",
    "usage_true_all = usage_true_all[:, context_len:-context_len, :] \n",
    "usage_mse = np.mean((usage_preds_all - usage_true_all) ** 2)\n",
    "print(f\"\\nUsage prediction:\")\n",
    "print(f\"  Mean squared error: {usage_mse:.6f}\")\n",
    "\n",
    "# Per-condition MSE\n",
    "for cond_idx in range(usage_preds_all.shape[-1]):\n",
    "    cond_mse = np.mean((usage_preds_all[..., cond_idx] - usage_true_all[..., cond_idx]) ** 2)\n",
    "    print(f\"  Condition {cond_idx} MSE: {cond_mse:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "splicevo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
