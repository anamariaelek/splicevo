{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4bcf21b",
   "metadata": {},
   "source": [
    "# Train small Splicevo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74981a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9090ebdc",
   "metadata": {},
   "source": [
    "## Simulate small dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d65ddbf",
   "metadata": {},
   "source": [
    "To train a Splicevo model, we need the following data:\n",
    "\n",
    "- Input DNA sequences of shape `B, L, 4` (one-hot encoded)\n",
    "- Labels of shape `B, L` corresponding to splice site annotations (0=not a splice site, 1=splice donor, 2=splice acceptor)\n",
    "- SSE values of shape `B, L, N` correspondint to splice site strength estimates in N different conditions (tissues, developmental time points)\n",
    "- Species vector of length `B` indicating the species for each sequence in the batch\n",
    "- Mappings of species indices to species names, and condition indices to condition names\n",
    "\n",
    "`B` is the batch size, `L` is the sequence length (consisting of core sequence `core_len` and `context_len` on both sides), and `N` is the number of conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987952d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate small dataset\n",
    "B = 256\n",
    "L = 2900\n",
    "core_len = 2000\n",
    "context_len = 450\n",
    "N = 5\n",
    "\n",
    "# Simulate random sequence input\n",
    "sequences = np.random.randint(0, 2, size=(B, L, 4)).astype(np.float32)\n",
    "\n",
    "# Simulate species assignment\n",
    "species = np.random.randint(0, 3, size = B).astype(np.int32)\n",
    "\n",
    "# Insert splice sites into random sequences\n",
    "def insert_splice_sites(sequences, donor_freq=0.1, acceptor_freq=0.1):\n",
    "    B = sequences.shape[0]\n",
    "    L = sequences.shape[1]\n",
    "    labels = np.zeros((B, L), dtype=np.int64)\n",
    "    for b in range(sequences.shape[0]):\n",
    "        donor_sites = np.random.randint(2, L, int(donor_freq * L))\n",
    "        acceptor_sites = np.random.randint(2, L, int(acceptor_freq * L))\n",
    "        for pos in donor_sites:\n",
    "            labels[b, pos] = 1\n",
    "            sequences[b, pos-2:pos, :] = [[0, 0, 1, 0],[0, 0, 0, 1]]  # 'GT' donor site\n",
    "        for pos in acceptor_sites:\n",
    "            labels[b, pos] = 2\n",
    "            sequences[b, pos-2:pos, :] = [[1, 0, 0, 0],[0, 0, 1, 0]]  # 'AG' acceptor site\n",
    "    return sequences, labels\n",
    "\n",
    "sequences, labels = insert_splice_sites(sequences)\n",
    "\n",
    "# Print number of sites per species\n",
    "for i in np.unique(species):\n",
    "    labels_i = labels[species == i]\n",
    "    print(f\"Species {i}: {labels_i.shape[0]} sequences\" )\n",
    "    for site_type in range(3):\n",
    "        print(f\"  site type {site_type}: {labels_i[labels_i == site_type].shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce2f3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate SSE values distribution \n",
    "sse = np.random.beta(2, 0.5, size=(B, L, N)).astype(np.float32)\n",
    "# Set non-splice positions to zero SSE\n",
    "sse[labels == 0] = 0\n",
    "# Set a fraction of splice positions to zero SSE\n",
    "splice_positions = np.where(labels > 0)\n",
    "num_zero_sse = int(0.3 * len(splice_positions[0]))\n",
    "zero_sse_indices = np.random.choice(len(splice_positions[0]), num_zero_sse, replace=False)\n",
    "sse[splice_positions[0][zero_sse_indices], splice_positions[1][zero_sse_indices], np.random.randint(0, N, size=1)] = 0\n",
    "\n",
    "# Plot SSE distribution\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(sse[labels > 0].flatten(), bins=50)\n",
    "plt.xlabel('SSE value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac000b08",
   "metadata": {},
   "source": [
    "Split dataset into train (80%) and test (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0351d990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test/validation split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Split into train+val and test (80/20)\n",
    "train_val_idx, test_idx = train_test_split(\n",
    "    np.arange(len(sequences)),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split train+val into train and validation (80/20 of train+val = 64/16 overall)\n",
    "train_idx, val_idx = train_test_split(\n",
    "    train_val_idx,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train set size: {len(train_idx)}\")\n",
    "print(f\"Validation set size: {len(val_idx)}\")\n",
    "print(f\"Test set size: {len(test_idx)}\")\n",
    "\n",
    "# Create train, validation, and test sets\n",
    "train_sequences, train_labels, train_sse, train_species = (\n",
    "    sequences[train_idx], labels[train_idx], sse[train_idx], species[train_idx]\n",
    ")\n",
    "val_sequences, val_labels, val_sse, val_species = (\n",
    "    sequences[val_idx], labels[val_idx], sse[val_idx], species[val_idx]\n",
    ")\n",
    "test_sequences, test_labels, test_sse, test_species = (\n",
    "    sequences[test_idx], labels[test_idx], sse[test_idx], species[test_idx]\n",
    ")\n",
    "\n",
    "# Create datasets\n",
    "from splicevo.training import SpliceDataset\n",
    "\n",
    "train_dataset = SpliceDataset(train_sequences, train_labels, train_sse, train_species)\n",
    "val_dataset = SpliceDataset(val_sequences, val_labels, val_sse, val_species)\n",
    "test_dataset = SpliceDataset(test_sequences, test_labels, test_sse, test_species)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"\\nData loaders created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e954160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count splice sites in each set\n",
    "def count_splice_sites(labels):\n",
    "    donor_count = np.sum(labels == 1)\n",
    "    acceptor_count = np.sum(labels == 2)\n",
    "    return donor_count, acceptor_count\n",
    "train_donors, train_acceptors = count_splice_sites(train_labels)\n",
    "val_donors, val_acceptors = count_splice_sites(val_labels)\n",
    "test_donors, test_acceptors = count_splice_sites(test_labels)\n",
    "print(f\"Train set: {train_donors} donors, {train_acceptors} acceptors\")\n",
    "print(f\"Validation set: {val_donors} donors, {val_acceptors} acceptors\")\n",
    "print(f\"Test set: {test_donors} donors, {test_acceptors} acceptors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2742c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot SSE distribution for splice sites in each set\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(train_sse[train_labels > 0].flatten(), bins=50)\n",
    "plt.title('Train Set SSE Distribution')\n",
    "plt.xlabel('SSE value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(val_sse[val_labels > 0].flatten(), bins=50)\n",
    "plt.title('Validation Set SSE Distribution')\n",
    "plt.xlabel('SSE value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(test_sse[test_labels > 0].flatten(), bins=50)\n",
    "plt.title('Test Set SSE Distribution')\n",
    "plt.xlabel('SSE value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abf4578",
   "metadata": {},
   "source": [
    "## Train Splicevo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7167bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from splicevo.model import SplicevoModel\n",
    "from splicevo.training import SpliceTrainer, SpliceDataset\n",
    "import torch\n",
    "\n",
    "# Model configuration\n",
    "model_config = {\n",
    "    'embed_dim': 128,\n",
    "    'num_resblocks': 16,\n",
    "    'dilation_strategy': 'alternating',\n",
    "    'alternate': 4,\n",
    "    'num_classes': 3,\n",
    "    'n_conditions': N,\n",
    "    'context_len': context_len,\n",
    "    'num_heads': 8,\n",
    "    'dropout': 0.3,\n",
    "    'usage_loss_type': 'weighted_mse',\n",
    "    'n_species': len(np.unique(species))\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "model = SplicevoModel(**model_config)\n",
    "print(\"Model initialized:\")\n",
    "print(f\"  Encoder: Conv blocks with multi-scale fusion\")\n",
    "print(f\"  Transformer: {model_config['num_heads']} attention heads\")\n",
    "print(f\"  Output heads: Splice classification + SSE prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bce7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "training_config = {\n",
    "    'learning_rate': 1.0e-3,\n",
    "    'weight_decay': 1.0e-3,\n",
    "    'num_epochs': 100,\n",
    "    'splice_weight': 0.5,\n",
    "    'usage_weight': 0.5,\n",
    "    'weighted_mse_extreme_low': 0.1,\n",
    "    'weighted_mse_extreme_high': 0.9,\n",
    "    'weighted_mse_extreme_weight': 5.0,\n",
    "    'early_stopping_patience': 10\n",
    "}\n",
    "\n",
    "# Create trainer\n",
    "trainer = SpliceTrainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    learning_rate=training_config['learning_rate'],\n",
    "    weight_decay=training_config['weight_decay'],\n",
    "    splice_weight=training_config['splice_weight'],\n",
    "    usage_weight=training_config['usage_weight'],\n",
    "    weighted_mse_extreme_low=training_config['weighted_mse_extreme_low'],\n",
    "    weighted_mse_extreme_high=training_config['weighted_mse_extreme_high'],\n",
    "    weighted_mse_extreme_weight=training_config['weighted_mse_extreme_weight'],\n",
    "    usage_loss_type=model_config['usage_loss_type'],\n",
    ")\n",
    "\n",
    "print(\"Trainer created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57645387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "print(\"Training model...\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "history = trainer.train(\n",
    "    n_epochs=training_config['num_epochs'],\n",
    "    early_stopping_patience=training_config['early_stopping_patience']\n",
    ")\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36923850",
   "metadata": {},
   "source": [
    "# Predict with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442ca20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model in evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0dfb7f",
   "metadata": {},
   "source": [
    "Calculate predictions on the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7f2c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_splice_preds = []\n",
    "all_splice_true = []\n",
    "all_usage_preds = []\n",
    "all_usage_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_loader):\n",
    "        sequences = batch['sequences'].to(device)\n",
    "        splice_labels = batch['splice_labels'].to(device)\n",
    "        usage_targets = batch['usage_targets'].to(device)\n",
    "        species_ids = batch['species_ids'].to(device) if 'species_ids' in batch else None\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(sequences, species_ids=species_ids)\n",
    "        \n",
    "        # Get predictions\n",
    "        splice_logits = outputs['splice_logits']  # (batch, central_len, num_classes)\n",
    "        splice_preds = torch.argmax(splice_logits, dim=-1)  # (batch, central_len)\n",
    "        \n",
    "        usage_preds = torch.sigmoid(outputs['usage_predictions'])  # (batch, central_len, n_conditions)\n",
    "        \n",
    "        # Move to CPU and convert to numpy\n",
    "        all_splice_preds.append(splice_preds.cpu().numpy())\n",
    "        all_splice_true.append(splice_labels.cpu().numpy())\n",
    "        all_usage_preds.append(usage_preds.cpu().numpy())\n",
    "        all_usage_true.append(usage_targets.cpu().numpy())\n",
    "        \n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"  Processed {batch_idx + 1}/{len(test_loader)} batches\")\n",
    "\n",
    "# Concatenate all predictions\n",
    "splice_preds_all = np.concatenate(all_splice_preds)  # (n_test, central_len)\n",
    "splice_true_all = np.concatenate(all_splice_true)    # (n_test, central_len)\n",
    "usage_preds_all = np.concatenate(all_usage_preds)    # (n_test, central_len, n_conditions)\n",
    "usage_true_all = np.concatenate(all_usage_true)      # (n_test, central_len, n_conditions)\n",
    "\n",
    "print(f\"\\nPredictions collected:\")\n",
    "print(f\"  Splice predictions shape: {splice_preds_all.shape}\")\n",
    "print(f\"  Splice ground truth shape: {splice_true_all.shape}\")\n",
    "print(f\"  Usage predictions shape: {usage_preds_all.shape}\")\n",
    "print(f\"  Usage ground truth shape: {usage_true_all.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b454d69",
   "metadata": {},
   "source": [
    "Compute evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6166829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Flatten for overall accuracy\n",
    "splice_preds_flat = splice_preds_all.flatten()\n",
    "splice_true_flat = splice_true_all.flatten()\n",
    "\n",
    "accuracy = accuracy_score(splice_true_flat, splice_preds_flat)\n",
    "print(f\"\\nSplice site classification:\")\n",
    "print(f\"  Overall accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Per-class metrics\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    splice_true_flat, splice_preds_flat, \n",
    "    labels=[0, 1, 2],\n",
    "    zero_division=0\n",
    ")\n",
    "class_names = ['Not splice', 'Donor', 'Acceptor']\n",
    "for i, name in enumerate(class_names):\n",
    "    print(f\"  {name:15} - Precision: {precision[i]:.4f}, Recall: {recall[i]:.4f}, F1: {f1[i]:.4f}\")\n",
    "\n",
    "# Usage prediction metrics (MSE)\n",
    "usage_mse = np.mean((usage_preds_all - usage_true_all) ** 2)\n",
    "print(f\"\\nUsage prediction:\")\n",
    "print(f\"  Mean squared error: {usage_mse:.6f}\")\n",
    "\n",
    "# Per-condition MSE\n",
    "for cond_idx in range(usage_preds_all.shape[-1]):\n",
    "    cond_mse = np.mean((usage_preds_all[..., cond_idx] - usage_true_all[..., cond_idx]) ** 2)\n",
    "    print(f\"  Condition {cond_idx} MSE: {cond_mse:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9016bffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(splice_true_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2cfab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(splice_preds_flat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "splicevo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
