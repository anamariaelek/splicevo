#!/usr/bin/env python3
"""
Run TF-MoDISco analysis on saved attributions (splice and usage).

This script performs:
1. Load saved attributions from files generated by save_attributions_for_modisco
2. Run TF-MoDISco motif discovery on splice attributions (by_site_type)
3. Run TF-MoDISco motif discovery on usage attributions (by_condition)
4. Extract motifs and generate reports for each analysis
5. Save all results to disk

Usage:
    python run_modisco_analysis.py \
        --attributions-base PATH_BASE \
        --output OUTPUT_DIR \
        --sliding-window-size SIZE \
        --flank-size SIZE \
        --target-seqlet-fdr FDR \
        --n-cores N_CORES
        
Example:
    python run_modisco_analysis.py \
        --attributions-base /path/to/attributions \
        --output ./modisco_results \
        --n-cores 4
"""

import argparse
import json
import sys
from pathlib import Path
from datetime import datetime

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))

from splicevo.attributions import (
    analyze_saved_attributions_quick, ModiscoConfig
)


def run_modisco_analysis(base_path, output_dir, 
                         sliding_window_size=12, 
                         flank_size=5, 
                         target_seqlet_fdr=0.01, 
                         min_metacluster_size=100,
                         max_seqlets_per_metacluster=20000,
                         trim_to_window_size=12, 
                         initial_flank_to_add=5,
                         min_passing_windows_frac=0.03,
                         max_passing_windows_frac=0.2,
                         n_cores=4, verbose=True):
    """Run TF-MoDISco analysis on both splice and usage attributions."""
    print("Running TF-MoDISco analysis on splice and usage attributions")
    
    # Configure
    print("\nConfiguring TF-MoDISco...")
    config = ModiscoConfig(
        sliding_window_size=sliding_window_size,
        flank_size=flank_size,
        min_passing_windows_frac=min_passing_windows_frac,
        max_passing_windows_frac=max_passing_windows_frac,
        target_seqlet_fdr=target_seqlet_fdr,
        min_metacluster_size=min_metacluster_size,
        max_seqlets_per_metacluster=max_seqlets_per_metacluster,
        trim_to_window_size=trim_to_window_size,
        initial_flank_to_add=initial_flank_to_add,
        n_processing_cores=n_cores,
    )
    print(f"  sliding_window_size: {config.sliding_window_size}")
    print(f"  flank_size: {config.flank_size}")
    print(f"  min_passing_windows_frac: {config.min_passing_windows_frac}")
    print(f"  max_passing_windows_frac: {config.max_passing_windows_frac}")
    print(f"  target_seqlet_fdr: {config.target_seqlet_fdr}")
    print(f"  min_metacluster_size: {config.min_metacluster_size}")
    print(f"  max_seqlets_per_metacluster: {config.max_seqlets_per_metacluster}")
    print(f"  trim_to_window_size: {config.trim_to_window_size}")
    print(f"  initial_flank_to_add: {config.initial_flank_to_add}")
    print(f"  n_processing_cores: {config.n_processing_cores}")
    
    # Prepare output directory
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    results = {}
    
    # Run analysis on splice attributions (by site type)
    print(f"\n1. Running TF-MoDISco analysis on splice attributions by site type...")
    # Construct path for splice files (e.g., base_path/splice)
    base_path_obj = Path(base_path)
    splice_base_path = base_path_obj / "splice" if not str(base_path).endswith("splice") else base_path_obj
    splice_output_dir = output_dir / "splice_by_site_type"
    
    print(f"  Base path: {splice_base_path}")
    splice_analyzer = analyze_saved_attributions_quick(
        base_path=splice_base_path,
        aggregation='by_site_type',
        output_dir=splice_output_dir,
        config=config,
        verbose=verbose
    )
    results['splice_by_site_type'] = {
        'analyzer': splice_analyzer,
        'output_dir': splice_output_dir,
    }
    
    # Run analysis on usage attributions (by condition)
    print(f"\n2. Running TF-MoDISco analysis on usage attributions by condition...")
    # Construct path for usage files (e.g., base_path/usage)
    usage_base_path = base_path_obj / "usage" if not str(base_path).endswith("usage") else base_path_obj
    usage_output_dir = output_dir / "usage_by_condition"
    
    print(f"  Base path: {usage_base_path}")
    usage_analyzer = analyze_saved_attributions_quick(
        base_path=usage_base_path,
        aggregation='by_condition',
        output_dir=usage_output_dir,
        config=config,
        verbose=verbose
    )
    results['usage_by_condition'] = {
        'analyzer': usage_analyzer,
        'output_dir': usage_output_dir,
    }
    
    return results


def extract_motifs_and_reports(results):
    """Extract motifs and generate reports for all analyses."""
    print("\n3. Extracting motifs and generating reports")
    
    all_motif_results = {}
    
    for analysis_name, analysis_data in results.items():
        analyzer = analysis_data['analyzer']
        output_dir = analysis_data['output_dir']
        
        print(f"\n{analysis_name}:")
        
        for name, result in analyzer.results.items():
            print(f"  {name}:")
            print(f"    Status: {result['status']}")
            
            if result['status'] != 'complete':
                print(f"    ✗ Analysis failed")
                continue
            
            # Motif summary
            motif_summary = result.get('motif_summary', {})
            n_pos = motif_summary.get('n_pos_patterns', 0)
            n_neg = motif_summary.get('n_neg_patterns', 0)
            print(f"    ✓ Patterns: {n_pos} positive, {n_neg} negative")
            
            # Extract motifs from HDF5
            if result.get('h5_path'):
                h5_path = result['h5_path']
                
                try:
                    motifs = analyzer.extract_motifs_from_h5(h5_path)
                    all_motif_results[f"{analysis_name}_{name}"] = motifs
                    
                    n_pos_motifs = len(motifs['pos_patterns'])
                    n_neg_motifs = len(motifs['neg_patterns'])
                    print(f"    ✓ Motifs extracted: {n_pos_motifs} positive, "
                          f"{n_neg_motifs} negative")
                    
                    # Show details about first motif
                    if motifs['pos_patterns']:
                        first_motif = motifs['pos_patterns'][0]
                        print(f"      First positive motif: {first_motif['name']}")
                        if first_motif['sequence'] is not None:
                            print(f"        Sequence shape: {first_motif['sequence'].shape}")
                    
                    # Generate reports
                    report_dir = output_dir / f"{name}_report"
                    analyzer.generate_reports(h5_path, report_dir)
                    print(f"    ✓ Reports: {report_dir}")
                except Exception as e:
                    print(f"    ⚠ Could not extract motifs: {e}")
            else:
                print(f"    ⚠ No HDF5 file saved")
    
    return all_motif_results


def save_summary(results, output_dir):
    """Save analysis summary for all analyses."""
    print("\n4. Saving analysis summaries")
    
    output_dir = Path(output_dir)
    
    all_summaries = {}
    summary_paths = []
    
    for analysis_name, analysis_data in results.items():
        analyzer = analysis_data['analyzer']
        
        # Get summary for this analysis
        summary = analyzer.get_summary()
        all_summaries[analysis_name] = summary
        
        # Save to JSON
        summary_path = output_dir / f"{analysis_name}_summary.json"
        with open(summary_path, 'w') as f:
            # Convert to JSON-serializable format
            json_summary = {}
            for name, info in summary.items():
                json_summary[name] = {k: str(v) for k, v in info.items()}
            json.dump(json_summary, f, indent=2)
        
        print(f"\n  {analysis_name}:")
        print(f"    Summary saved to: {summary_path}")
        summary_paths.append(summary_path)
        
        # Print summary
        for name, info in summary.items():
            print(f"    {name}:")
            for key, value in info.items():
                print(f"      {key}: {value}")
    
    return summary_paths


def main():
    parser = argparse.ArgumentParser(
        description="Run TF-MoDISco analysis on saved splice and usage attribution files",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument(
        '--attributions-base', required=True,
        help='Base path for saved attribution files. '
             'Will automatically look for {path}_splice_* and {path}_usage_* files'
    )
    parser.add_argument(
        '--output', required=True,
        help='Output directory for TF-MoDISco results'
    )
    parser.add_argument(
        '--sliding-window-size', type=int, default=12,
        help='Sliding window size (default: 12)'
    )
    parser.add_argument(
        '--flank-size', type=int, default=5,
        help='Flank size (default: 5)'
    )
    parser.add_argument(
        '--target-seqlet-fdr', type=float, default=0.01,
        help="Target FDR (default: 0.01)"
    )
    parser.add_argument(
        '--min-metacluster-size', type=int, default=100,
        help="Minimum size of metacluster (default: 100)"
    )
    parser.add_argument(
        '--max-seqlets-per-metacluster', type=int, default=20000,
        help="Maximum number of seqlets per metacluster (default: 20000)"
    )
    parser.add_argument(
        '--trim-to-window-size', type=int, default=12,
        help="Trim patterns to initial window size (default: 12)"
    )
    parser.add_argument(
        '--initial-flank-to-add', type=int, default=5,
        help="Initial flank to add to each side of patterns (default: 5)"
    )
    parser.add_argument(
        '--min-passing-windows-frac', type=float, default=0.03,
        help="Minimum fraction of passing windows (default: 0.03)"
    )
    parser.add_argument(
        '--max-passing-windows-frac', type=float, default=0.2,
        help="Maximum fraction of passing windows (default: 0.2)"
    )
    parser.add_argument(
        '--n-cores', type=int, default=4,
        help='Number of processing cores (default: 4)'
    )
    parser.add_argument(
        '--verbose', action='store_true',
        help='Print verbose output'
    )
    args = parser.parse_args()
    
    print(f"\nTF-MoDISco Analysis on Splice and Usage Attributions")
    print(f"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    try:
        # Create output directory
        output_dir = Path(args.output)
        output_dir.mkdir(parents=True, exist_ok=True)
        print(f"\nOutput directory: {output_dir}")
        
        # Run modisco analysis on both splice and usage attributions
        results = run_modisco_analysis(
            base_path=args.attributions_base,
            output_dir=output_dir,
            sliding_window_size=args.sliding_window_size,
            flank_size=args.flank_size,
            target_seqlet_fdr=args.target_seqlet_fdr,
            max_seqlets_per_metacluster=args.max_seqlets_per_metacluster,
            min_metacluster_size=args.min_metacluster_size,
            trim_to_window_size=args.trim_to_window_size,
            initial_flank_to_add=args.initial_flank_to_add,
            min_passing_windows_frac=args.min_passing_windows_frac,
            max_passing_windows_frac=args.max_passing_windows_frac,
            n_cores=args.n_cores,
            verbose=args.verbose
        )
        
        # Extract motifs and generate reports
        motif_results = extract_motifs_and_reports(results)
        
        # Save summaries
        summary_paths = save_summary(results, output_dir)
        
        print("\n" + "="*60)
        print("✓ Analysis Complete!")
        print("="*60)
        print(f"Results saved to: {output_dir}")
        for i, path in enumerate(summary_paths, 1):
            print(f"Summary {i}: {path}")
        print(f"Finished: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        return 0
    
    except Exception as e:
        print(f"\n✗ Error: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    sys.exit(main())
